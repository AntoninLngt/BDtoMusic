{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23bf454b"
   },
   "source": [
    "# Projet Informatique - Comics to Music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc957ad1"
   },
   "source": [
    "## GANs non-conditionnel\n",
    "\n",
    "Dans le code, en voici les différents éléments :\n",
    " - définition du générateur\n",
    " - définition du discriminateur\n",
    " - entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.139819Z",
     "iopub.status.busy": "2025-12-22T22:22:10.139529Z",
     "iopub.status.idle": "2025-12-22T22:22:10.143902Z",
     "shell.execute_reply": "2025-12-22T22:22:10.143186Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.139795Z"
    },
    "id": "ba38af79",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.155074Z",
     "iopub.status.busy": "2025-12-22T22:22:10.154523Z",
     "iopub.status.idle": "2025-12-22T22:22:10.163048Z",
     "shell.execute_reply": "2025-12-22T22:22:10.162257Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.155050Z"
    },
    "id": "c0a92317",
    "outputId": "28a1ba71-a5f6-4550-a2db-8cc19f1c36a7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu126\n",
      "CUDA disponible: True\n",
      "Nom du GPU: Tesla P100-PCIE-16GB\n",
      "Device final: cuda\n"
     ]
    }
   ],
   "source": [
    "# IMPORT GPU sur google colab\n",
    "\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Nom du GPU: {torch.cuda.get_device_name(0)}\") # Devrait afficher 'Tesla T4'\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"❌ GPU toujours pas détecté.\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Device final: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78d8be52"
   },
   "source": [
    "### Générateur (sans conditionnement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.178327Z",
     "iopub.status.busy": "2025-12-22T22:22:10.178075Z",
     "iopub.status.idle": "2025-12-22T22:22:10.185880Z",
     "shell.execute_reply": "2025-12-22T22:22:10.185300Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.178282Z"
    },
    "id": "49e73c7c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NonConditionnalGenerator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        '''On commence par définir les éléments structurels de notre générateur.\n",
    "        Dans notre cas, on suppose d'abord qu'on veut générer vers un espace latent\n",
    "        (génération conditionnée par la suite par un autre espace latent, plus des\n",
    "        conditions supplémentaires).\n",
    "        Le générateur va augmenter la dimension des données en opérant une déconvolution (Upsample, 2e article cGANs)\n",
    "        Ici, on part d'un vecteur bruit z et on utilise une première couche linéaire pour\n",
    "        le mettre sous format-image en 2D. Dans cet exemple, on veut obtenir des images 28x28, donc on transforme z\n",
    "        en images 7x7, ce qui permettra facilement d'atteindre la dimension finale en réalisant deux Upsample de scale = 2\n",
    "        '''\n",
    "\n",
    "        self.z_dim = z_dim # dimension du vecteur bruit\n",
    "        self.init_dim = 7 # dans cet exemple, on veut partir d'une image 7x7\n",
    "        self.num_ch = 128 # nombre de canaux arbitraire (dépend de l'espace latent, peut être des autres conditions)\n",
    "        self.l1 = nn.Sequential( # première couche linéaire\n",
    "            nn.Linear(z_dim, self.num_ch * self.init_dim * self.init_dim) # on change la dimension du bruit pour pouvoir le\n",
    "                                                                          #reshape en [num_ch] images de dimensions init_dim x init_dim\n",
    "        )\n",
    "\n",
    "        # Réseau convolutionnel pour générer une image 28x28  : G_non_conditionnel : bruit --> espace latent audio\n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.num_ch),\n",
    "            nn.Upsample(scale_factor=2), # passer de 7x7 à 14x14\n",
    "            nn.Conv2d(self.num_ch, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2), # on passe à 28x28\n",
    "            nn.Conv2d(256, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        ######################\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conversion du vecteur bruit\n",
    "        output1 = self.l1(x)\n",
    "        # reshape en image\n",
    "        output2 = output1.view(output1.shape[0], self.num_ch, self.init_dim, self.init_dim)\n",
    "        # CNN\n",
    "        output = self.model(output2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e402e731"
   },
   "source": [
    "### Discriminateur (sans conditionnement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.187334Z",
     "iopub.status.busy": "2025-12-22T22:22:10.187056Z",
     "iopub.status.idle": "2025-12-22T22:22:10.203779Z",
     "shell.execute_reply": "2025-12-22T22:22:10.203059Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.187287Z"
    },
    "id": "8c6e6133",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NonConditionnalDiscriminator(nn.Module):\n",
    "    def __init__(self, num_ch):\n",
    "        super().__init__()\n",
    "\n",
    "        '''Le discriminateur va être entraîner pour différencier les données réelles (espace latent audio)\n",
    "        des données générées (G(z), qui dans la version cGAN seront conditionnées par l'espace latent BD).\n",
    "        En pratique, il ne prend ne prend en entrée que des vrais ou que des faux à la fois.\n",
    "        Fonctionnement de l'entraînement :\n",
    "         - on génère les prédictions D(x_real) --> objectif D(x_real) = 1\n",
    "         - on calcule la loss sur les prédictions réelles : loss_real = loss(D(x_real), 1)\n",
    "         - on génère les prédictions D(x_fake) --> objectif D(x_fake) = 1\n",
    "         - on calcule la loss sur les prédictions réelles : loss_fake = loss(D(x_fake), 1)\n",
    "        Le discriminateur est donc entraîné sur loss_tot = (loss_real + loss_fake)\n",
    "\n",
    "        Architecture : réseau convolutionnel classique, exemple dans le deuxième article sur les cGANs'''\n",
    "\n",
    "        self.num_ch = num_ch # nombre de canaux, dépend de l'espace latent audio\n",
    "\n",
    "        #  modèle de convolution classique, on cherche à densifier l'information des images à chaque couche\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(num_ch, 64, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 512, kernel_size=3, stride=2, padding=1), nn.BatchNorm2d(512), nn.LeakyReLU(0.2),\n",
    "\n",
    "            # A la fin, on réduit brusquement le nombre de canaux à 1, pour obtenir une prédiction scalire {0,1}.\n",
    "            # Dans la version cGAN, c'est ici que l'on introduit la condition y !!!\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # prend un batch d'images d'entrée, sort un batch de 1 et de 0\n",
    "        output = self.model(x).view(-1,1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51774a4d"
   },
   "source": [
    "### Entraînement (sans conditionnement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.205435Z",
     "iopub.status.busy": "2025-12-22T22:22:10.205210Z",
     "iopub.status.idle": "2025-12-22T22:22:10.221226Z",
     "shell.execute_reply": "2025-12-22T22:22:10.220509Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.205416Z"
    },
    "id": "e06bcc47",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Sauvegarde et récupération de G et D\n",
    "# if os.path.isfile('discriminator2.pt') and os.path.isfile('generator2.pt'):\n",
    "#     nc_discriminator.load_state_dict(torch.load('./discriminator2.pt'))\n",
    "#     nc_generator.load_state_dict(torch.load('./generator2.pt'))\n",
    "\n",
    "# else:\n",
    "#     for epoch in range(num_epochs):\n",
    "\n",
    "#         for n, (real_samples, _) in enumerate(train_loader):\n",
    "\n",
    "#             ### Entraînement nc_discriminator\n",
    "#             # On récupère les données réelles (reshape pour être sûr qu'elles soient acceptés par nc_D)\n",
    "#             real_samples = real_samples.view(-1, 1, 28, 28)\n",
    "\n",
    "#             # on génère les fake_samples à partir d'un bruit gaussien (pas de condition ici)\n",
    "#             z = torch.randn(batch_size, z_dim)\n",
    "#             fake_samples = torch.tanh(nc_generator(z))\n",
    "\n",
    "#             # Initialisation de la descente de gradient\n",
    "#             optimizer_nc_discriminator.zero_grad()\n",
    "\n",
    "#             # Loss sur les prédictions \"données réelles\"\n",
    "#             predict_real = nc_discriminator(real_samples)\n",
    "#             loss_real = loss_function(predict_real, torch.full((batch_size, 1), 1.0))\n",
    "\n",
    "#             # Loss sur les prédictions \"données générées\"\n",
    "#             predict_fake = nc_discriminator(fake_samples.detach())\n",
    "#             loss_fake = loss_function(predict_fake, torch.full((batch_size, 1), 0.0))\n",
    "\n",
    "#             # Loss complète\n",
    "#             loss_discriminator = (loss_real + loss_fake) / 2\n",
    "\n",
    "#             # Descente de gradient et mise à jour des poids w_D\n",
    "#             loss_discriminator.backward()\n",
    "#             optimizer_nc_discriminator.step()\n",
    "\n",
    "#             ### Entraînement nc_generator\n",
    "#             # Initialisation descente de gradient\n",
    "#             optimizer_nc_generator.zero_grad()\n",
    "\n",
    "#             # génération des fake_samples\n",
    "#             z = torch.randn(batch_size, 100)\n",
    "#             fake_samples_new = nc_generator(z)\n",
    "\n",
    "#             # récupération de la prédiction de D\n",
    "#             gen_prediction = nc_discriminator(fake_samples_new)\n",
    "\n",
    "#             # loss classique entre la prédiction D(fake_samples) et l'objectid vecteur de 1\n",
    "#             valid_labels = torch.full((batch_size, 1), 1.0)\n",
    "#             loss_generator = loss_function(gen_prediction, valid_labels)\n",
    "\n",
    "#             # OPTIONNEL --> diversity loss\n",
    "#             # on ajoute une diversity loss pour éviter de générer que des points identiques\n",
    "#             # sinon le générateur peut mapper à chaque fois vers une seule image qui à l'air vraie\n",
    "#             distances = torch.cdist(fake_samples_new, fake_samples_new, p=2) # renvoie la distance scalaire entre tous les éléments générés du batch\n",
    "#             mean_distance = torch.mean(distances)\n",
    "#             lambda_div = 0.2 # poids sur la loss\n",
    "#             loss_diversity = -lambda_div * mean_distance # on veut maximiser la distance donc on met un - devant\n",
    "\n",
    "#             # loss totale\n",
    "#             loss_generator = loss_generator + loss_diversity\n",
    "\n",
    "#             loss_generator.backward()\n",
    "#             optimizer_nc_generator.step()\n",
    "\n",
    "#             # Show loss\n",
    "#             if n == batch_size - 2:\n",
    "#                 print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
    "#                 print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deb370f9"
   },
   "source": [
    "## GANs conditionnels\n",
    "\n",
    "Pas si différents des GANs non-conditionnels, il faut juste rajouter une condition $y$ à deux étapes du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.222529Z",
     "iopub.status.busy": "2025-12-22T22:22:10.222164Z",
     "iopub.status.idle": "2025-12-22T22:22:10.238977Z",
     "shell.execute_reply": "2025-12-22T22:22:10.238322Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.222497Z"
    },
    "id": "766dae72",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConditionnalGenerator(nn.Module):\n",
    "    def __init__(self, z_dim, y_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.z_dim = z_dim # dimension du vecteur bruit\n",
    "        self.y_dim = y_dim # dimension du vecteur condition\n",
    "        self.init_dim = 7 # dans cet exemple, on veut partir d\"'une image 7x7\n",
    "        self.num_ch = 128 # nombre de canaux arbitraire (dépend de l'espace latent, peut être des autres conditions)\n",
    "\n",
    "        self.l1 = nn.Sequential( # première couche linéaire\n",
    "            nn.Linear(self.z_dim + self.y_dim, self.num_ch * self.init_dim * self.init_dim) # cette fois, on part de\n",
    "                                                                                            # z_dim + y_dim\n",
    "        )\n",
    "\n",
    "        # Réseau convolutionnel identique au vanilla GAN\n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.num_ch),\n",
    "            nn.Upsample(scale_factor=2), # passer de 7x7 à 14x14\n",
    "            nn.Conv2d(self.num_ch, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2), # on passe à 28x28\n",
    "            nn.Conv2d(256, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        ######################\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ici, x est la concaténation du bruit z et de la condition y\n",
    "        # conversion du vecteur x\n",
    "        output1 = self.l1(x)\n",
    "        # reshape en image\n",
    "        output2 = output1.view(output1.shape[0], self.num_ch, self.init_dim, self.init_dim)\n",
    "        # CNN\n",
    "        output = self.model(output2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.240509Z",
     "iopub.status.busy": "2025-12-22T22:22:10.240246Z",
     "iopub.status.idle": "2025-12-22T22:22:10.257135Z",
     "shell.execute_reply": "2025-12-22T22:22:10.256627Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.240477Z"
    },
    "id": "c3b99924",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConditionnalDiscriminator(nn.Module):\n",
    "    def __init__(self, num_ch, latent_x_dim, y_cond_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_ch = num_ch # nombre de canaux, dépend de l'espace latent audio\n",
    "        self.y_cond_dim = y_cond_dim\n",
    "        self.stride_size = 2 # valeur du stride pour connaître la dimension lors du reshape\n",
    "\n",
    "        #  modèle de convolution classique, on cherche à densifier l'information des images à chaque couche\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(num_ch, 64, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 512, kernel_size=3, stride=2, padding=1), nn.BatchNorm2d(512), nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        # A cette étape, il faut applatir les données et y concaténer la condition y\n",
    "        # calcul de la dimension du reshape :\n",
    "        self.image_dim = int(latent_x_dim / (self.stride_size ** 3)) # on a appliqué 3 strides de 2\n",
    "        self.flat_dim = 512 * self.image_dim * self.image_dim\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.flat_dim + self.y_cond_dim, 1), # ce n'est plus une convolution car vecteur plat\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # on rentre x et y car on commence par traiter seulement x avant d'injecter y\n",
    "        features = self.model(x)\n",
    "\n",
    "        # Aplatissement vers la flat dimension\n",
    "        features_flat = features.view(features.size(0), -1)\n",
    "\n",
    "        # Concaténation avec le vecteur condition y\n",
    "        combined = torch.cat([features_flat, y], dim=1)\n",
    "\n",
    "        # Prédiction finale\n",
    "        output = self.classifier(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02ba0ab4"
   },
   "source": [
    "## GANs Cycle-Consistent\n",
    "\n",
    "Dans notre cas, on veut que le GAN apprennent à générer des données dans l'espace latent $Y$ (audio) en étant influencé par l'espace latent $X$ (BDs). Pour cela, deux solutions : entraîner notre GAN avec des données réelles pairées, en conservant les paires dans les espaces latents $X$ et $Y$. Problème : auncun dataset existant possédant des paires d'audio et de BDs. On va donc chercher à entraîner notre GAN pour qu'il puisse associer des échantillons $x\\in \\{x_i\\}$ à des échantillons $y\\in\\{y_i\\}$, de manière non supervisée, en détectant lui-même les caractéristiques pour associer une paire. On s'inspire de l'article *Unpaired Image-to-Image Translation\n",
    "using Cycle-Consistent Adversarial Networks*, qui introduisent les *Cycle-Consistent GANs*. Ils utilisent ce réseau pour passer d'images à images. Dans notre cas, les espaces $X$ et $Y$ ne sont pas aussi similaires, il va peut être falloir injecter des conditions supplémentaires (structure, rythme, couleur, texte, sens --> CLIP), pour aider notre GAN à générer des paires qui ont du sens.\n",
    "\n",
    "En pratique, on a besoin d'entraîner deux générateurs\n",
    "$$\n",
    "G : X \\longrightarrow Y \\\\\n",
    "F : Y \\longrightarrow X\n",
    "$$\n",
    "\n",
    "Chacun associé à un discrimnateur, qui va déterminer si la sortie du générateur correspond à l'espace réel cible. Là génération est donc entraînée par une adversarial loss. On s'inspire des travaux de *Improved Training of Wasserstein GANs* qui ont introduit les WGANs, utilisant une distance de Wasserstein comme adversarial loss.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}_{WGAN} (G, D_Y, X, Y) =\\: &\\mathbb{E}_{y\\sim p_{data}(y)}[D_Y(y)]\\\\ - \\: &\\mathbb{E}_{x\\sim p_{data}(x)}[D_Y(G(x))]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Contrairement à un GAN classique, on ne cherchera à prédire des 1 ou des 0. On va ici chercher à maximiser les écarts entre les score vrais ou faux. Nos discriminateurs sortent donc des vecteurs de score, et non pas des labels de prédiction. On en tire une loss pour les discriminateurs, et une pour les générateurs :\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}_D &= \\mathbb{E}[D(G(x))] - \\mathbb{E}[D(y)] + \\lambda_{GP}\\mathcal{L}_{GP}\\\\\n",
    "\\mathcal{L}_G &= -\\mathbb{E}[D(G(x))]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "où $\\mathcal{L}_{GP}$ est la $gradient \\: penalty$ introduite dans l'article WGANs (ils utilisent $\\lambda_{GP}=10$). Cette pénalité vise à empêcher la sortie du discriminateur d'avoir une norme différente de 1. Ils l'expriment comme :\n",
    "$$\n",
    "\\mathcal{L}_{GP} = \\mathbb{E}[(||\\nabla_{\\hat{y} = G(x)}D(G(x))||_2 -1)^2]\n",
    "$$\n",
    "Un aspect important de l'article est qu'il stipule que le discriminateur doit être entraîné plus souvent que le générateur. Environ 5 steps pour 1.\n",
    "\n",
    "\n",
    "L'architecture globale *Cycle-GANs* nécessite d'ajouter une *cycle-loss*, qui détermine si les données sont bien reconstruites lors de l'application successive de $G$ et $F$ :\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}_{cyc} =\\: &\\mathbb{E}_{x\\sim p_{data}(x)}[||F(G(x)) - x||]\\\\ + \\:&\\mathbb{E}_{y\\sim p_{data}(y)}[||G(F(y)) - y||]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Pour l'architecture, l'article *Cycle-GANs* s'inspire de Johnson et al. *Perceptual losses\n",
    "for real-time style transfer and super-resolution*. On y ajoute la notion développée dans l'article *LOGAN : Unpaired Shape Transform in Latent Overcomplete Space*, qui présente l'avantage de travailler avec des espaces *overcomplete* (réseaux dans lesquels la dimension a été fortement augmentée). Cela facilite le transport de masse optimale entre les deux distributions (--> coût égal *masse* x *distance(X,Y)*). Cet ajout agit avec la Wassertein-Loss pour empêcher le *mode-collapse* :\n",
    "\n",
    "1. Générateurs :\n",
    " - $\\longrightarrow$ donc pour ces GANs là, on n'augmente pas forcément la dimension comme vu dans les cGANs (on peut quand même modifier si jamais nos espaces $X$ et $Y$ n'ont pas les mêmes dimensions). Nos espaces latents auront peut être des dimensions différentes (par exemple : peut être besoin de plus grandes dimensions dans l'espace latent audio, si on utilise plein de conditions supplémentaires dans l'espace BD).\n",
    "\n",
    " 2. Discriminateurs :\n",
    " - $N\\times N$ Patch-GANs : faits pour discriminer des grosses images (1080p par exemple). Ils ne discriminent que sur des portions de $N$ par $N$. Peut être pas nécessaire pour nous si on travaille sur des espaces latents de faibles dimensions. Mais peux justement permettre de travailler sur des espaces latents plus complexes sans trop augmenter la charge de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f834b2ad"
   },
   "source": [
    "### Générateur $G$ : $X$(BDs) $\\longrightarrow$ $Y$(audios)\n",
    "\n",
    "$G$ part de $X$ l'espace latent BDs pour générer $Y$ l'espace latent audio. Comment on utilisera des conditions supplémentaires pour influencer la génération, on peut se permettre de ne garder que peut d'information dans $X$. Ainsi, on choisit de générer $X$ (partie VAE) comme un vecteur 1D plutôt que comme une image. On ne garde ainsi qu'une idée du style et on oublie les informations de structure spatiale qui seront utilisées plus efficacement dans les autres conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.257976Z",
     "iopub.status.busy": "2025-12-22T22:22:10.257784Z",
     "iopub.status.idle": "2025-12-22T22:22:10.299981Z",
     "shell.execute_reply": "2025-12-22T22:22:10.299243Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.257957Z"
    },
    "id": "f0fbf36e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator_G(nn.Module):\n",
    "    def __init__(self, z_dim, latent_x_dim, init_dim, ngf=256):\n",
    "        '''\n",
    "        Inputs :\n",
    "         - z_dim : dimension du vecteur bruit seed du générateur\n",
    "        Dimensions des espaces latents:\n",
    "         - latent_x_dim : dimension de l'espace latent X d'où est tirée la condition du générateur G.\n",
    "            On peut générer l'espace latent BDs comme un vecteur, car on ne veut l'utiliser que pour avoir une\n",
    "            notion du style\n",
    "         - pas besoin de prendre latent_y_dim pour connaître la dimension de l'objectif si l'architecture\n",
    "         est adaptée en fonction de la dimension de départ init_dim (voir juste en dessous)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.x_dim = latent_x_dim # dimension du vecteur condition (espace BDs X)\n",
    "        self.init_dim  = init_dim # dimension (H ou W)\n",
    "        self.main_ch = ngf \n",
    "\n",
    "\n",
    "        \n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(self.z_dim + self.x_dim, self.main_ch * self.init_dim * self.init_dim)\n",
    "        )\n",
    "\n",
    "        # le réseau est structuré en blocs séquentiel pour permettre l'injection de la condition x entre les convolutions\n",
    "        self.bloc1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.main_ch + self.x_dim),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            # injection de x\n",
    "            nn.Conv2d(self.main_ch + self.x_dim, self.main_ch, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.main_ch, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.bloc2 = nn.Sequential(\n",
    "            # injection de x\n",
    "            nn.Conv2d(self.main_ch + self.x_dim, self.main_ch // 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.main_ch // 2, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.bloc3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(self.main_ch // 2, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        # Concaténation sur la dimension 1\n",
    "        cat_xz = torch.cat([x, z], dim=1)\n",
    "        out = self.l1(cat_xz)\n",
    "        out = out.view(out.shape[0], self.main_ch, self.init_dim, self.init_dim)\n",
    "\n",
    "        # première inejction\n",
    "        x_img = x.unsqueeze(2).unsqueeze(3).expand(-1, -1, out.size(2), out.size(3))\n",
    "        out = torch.cat([out, x_img], dim=1) # concaténation\n",
    "        out = self.bloc1(out)\n",
    "\n",
    "        # deuxième injection\n",
    "        x_img = x.unsqueeze(2).unsqueeze(3).expand(-1, -1, out.size(2), out.size(3))\n",
    "        out = torch.cat([out, x_img], dim=1) # concaténation\n",
    "        out = self.bloc2(out)\n",
    "\n",
    "        output = self.bloc3(out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a7e9253"
   },
   "source": [
    "### Générateur $F$ : $Y$(audios) $\\longrightarrow$ $X$(BDs)\n",
    "\n",
    "Contrairement à $G$, qui développait les données, $F$ a pour but de compresser l'espace $Y$ vers $X$. On veut que les deux générateurs forment un équilibre lors de l'apprentissage. On a également les même dimensions que dans $G$, mais inversées. Il es dont logique que l'architecture de $F$ soit symétrique à celle de $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.301226Z",
     "iopub.status.busy": "2025-12-22T22:22:10.300929Z",
     "iopub.status.idle": "2025-12-22T22:22:10.317955Z",
     "shell.execute_reply": "2025-12-22T22:22:10.317365Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.301185Z"
    },
    "id": "ef4d7258",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator_F(nn.Module):\n",
    "    def __init__(self, z_dim, latent_x_dim, x_ch, y_ch, init_dim, nff=256):\n",
    "        '''\n",
    "        Inputs :\n",
    "         - latent_x_dim : dimension du vecteur de sortie (espace X)\n",
    "         - latent_y_dim : nombre de canaux de l'espace latent d'entrée Y\n",
    "         - z_dim        : dimension du bruit gaussien ajouté\n",
    "         - init_dim     : dimension spatiale de référence\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.x_dim = latent_x_dim\n",
    "        self.y_ch = y_ch\n",
    "        self.z_dim = z_dim\n",
    "        self.init_dim = init_dim\n",
    "        self.internal_ch = x_ch\n",
    "        self.nff = nff\n",
    "\n",
    "        # Le réseau prend maintenant en entrée canaux de Y + canaux de Z\n",
    "        input_channels = self.y_ch + self.z_dim\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(input_channels, self.nff, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # equivalent à un Downsample\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(self.nff, self.nff//4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.nff//4, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(self.nff//4, self.internal_ch, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.internal_ch),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.flat_dim = self.internal_ch * self.init_dim * self.init_dim\n",
    "\n",
    "        self.final_head = nn.Sequential(\n",
    "            nn.Linear(self.flat_dim, self.x_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_y, z):\n",
    "\n",
    "        # comme on ajoute z à une matrice 2D, il faut l'étendre (comme la condition X dans DY)\n",
    "        batch_size, _, h, w = input_y.size()\n",
    "        z_expanded = z.view(batch_size, -1, 1, 1).expand(batch_size, -1, h, w)\n",
    "        combined_input = torch.cat([input_y, z_expanded], dim=1)\n",
    "\n",
    "        features = self.model(combined_input)\n",
    "        features_flat = features.view(features.shape[0], -1)\n",
    "        output_x = self.final_head(features_flat)\n",
    "\n",
    "        return output_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b6d4ea8"
   },
   "source": [
    "### Discriminateur $D_Y$\n",
    "\n",
    "$D_Y$ vérifie que $G(x) = \\hat{y} \\approx y$.\n",
    "\n",
    "**Au final les discriminateurs ne prennent pas de conditions. $\\\\$ EXPLICATION :  la loss des discriminateurs est calculée d'abord sur des prédictions à partir d'entrées totalement vraies, puis sur des prédictions à partir d'entrées totalement fausses (ou inversement) le conditionnement fonctionne pour la prédiction à partir de données fausses, puisque l'on veut que  les données générées depuis l'autre espace soit notées en fonction de l'autre espace. Cependant, pour les prédictions à partir de données réelles, comme les données ne sont pas pairées, la conditions ne veut rien dire pour le discriminateur. Il ne veut donc même pas reconnaître ça comme une donnée réelle lors du calcul de la loss (à clarifier).**\n",
    "\n",
    "**Du coup, *Comment assurer que le modèle découvre une cohérence entre X et Y ?* On s'appuie pour cela sur la Cycle-loss, qui permet de retrouver les données d'un espace en appliquant les deux générations successives. Cette Loss oblige le modèle à lier les échantillons $x$ et $y$ qui lui permettront de reproduire le plus fidèlement les espaces à partir des générations (à clarifier)**.\n",
    "\n",
    "Le discriminateur va donc prendre en entrée des données 2D, on peut donc utiliser une structure patchGAN $N\\times N$, qui permettra de réduire la quantité de calculs de la discrimination, et d'avoir un espace latent $Y$ plus complexe.\n",
    "\n",
    "Un discriminateur de type PatchGAN ne sort pas un scalaire de prédiction mais une grille de prédiction pour chaque patche de données. La couche linéaire à la fin du discriminateur conditionnel vu juste avant doit donc nécessairement disparaître car on veut une sortie 2D pour le discriminateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.319848Z",
     "iopub.status.busy": "2025-12-22T22:22:10.319589Z",
     "iopub.status.idle": "2025-12-22T22:22:10.335248Z",
     "shell.execute_reply": "2025-12-22T22:22:10.334610Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.319827Z"
    },
    "id": "bd47a3ce",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Discriminator_DY(nn.Module):\n",
    "    def __init__(self, y_ch, ndf=64):\n",
    "        \"\"\"\n",
    "        y_ch : Canaux de l'image Y\n",
    "        ndf  : Nombre de filtres de base\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # Layer 1 : Y -> Features\n",
    "            nn.Conv2d(y_ch, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Layer 4 : Sortie PatchGAN (Grille 2D)\n",
    "            nn.Conv2d(ndf * 4, 1, kernel_size=4, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, y_input):\n",
    "        # Plus besoin de x_condition\n",
    "        return self.model(y_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd3f08ce"
   },
   "source": [
    "### Discriminateur $D_X$\n",
    "\n",
    "Ce discriminateur agit sur l'espace $X$. Les données sont donc 1D, et plus simples que pour $D_Y$, on n'a pas besoin d'utiliser un discriminateur de type PatchGAN. On utilise un discriminateur conditionnée classique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.336257Z",
     "iopub.status.busy": "2025-12-22T22:22:10.336020Z",
     "iopub.status.idle": "2025-12-22T22:22:10.349535Z",
     "shell.execute_reply": "2025-12-22T22:22:10.348881Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.336236Z"
    },
    "id": "ed31cbb5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator_DX(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim=512):\n",
    "        \"\"\"\n",
    "        x_dim      : Dimension du vecteur latent X (ex: 3)\n",
    "        hidden_dim : Taille de la couche cachée (Largeur du réseau)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "            nn.Linear(x_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Sortie : Score scalaire (pour WGAN)\n",
    "            nn.Linear(hidden_dim // 4, 1)\n",
    "            # Pas de Sigmoid ici pour un WGAN\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x doit être de forme (Batch, x_dim)\n",
    "\n",
    "        # Sécurité : on s'assure que l'entrée est bien aplatie\n",
    "        x_flat = x.view(x.size(0), -1)\n",
    "\n",
    "        output = self.model(x_flat)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7db3f21a"
   },
   "source": [
    "### Fonctions de pertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.350864Z",
     "iopub.status.busy": "2025-12-22T22:22:10.350410Z",
     "iopub.status.idle": "2025-12-22T22:22:10.368929Z",
     "shell.execute_reply": "2025-12-22T22:22:10.368360Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.350828Z"
    },
    "id": "aa1d12d9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def CycleLoss(real_samples, rec_samples):\n",
    "    loss_func = nn.L1Loss()\n",
    "    return loss_func(real_samples, rec_samples)\n",
    "\n",
    "def GradientPenalty(D, real_samples, fake_samples, device=device):\n",
    "    \"\"\"Calcul du Gradient Penalty pour WGAN-GP\"\"\"\n",
    "\n",
    "    # On adapte les dimensions de alpha pour qu'elles collent aux données (1D ou 2D)\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device) if len(real_samples.shape) == 4 else torch.rand(real_samples.size(0), 1, device=device)\n",
    "\n",
    "    # si c'est un vecteur 1D (X), alpha doit être (Batch, 1)\n",
    "    # si c'est un tensuer 2D (Y), alpha doit être (Batch, 1, 1, 1) pour le broadcast\n",
    "    if len(real_samples.shape) == 2:\n",
    "         alpha = alpha.view(real_samples.size(0), 1)\n",
    "\n",
    "    # Interpolation\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    # Passage dans le discriminateur\n",
    "    d_interpolates = D(interpolates)\n",
    "\n",
    "    # Calcul du gradient\n",
    "    # On crée un vecteur de 1 --> cible de notre gradient\n",
    "    fake = torch.ones(d_interpolates.size(), device=device, requires_grad=False)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    # Calcul de la pénalité\n",
    "    gradients = gradients.view(gradients.size(0), -1) # on aplatit pour le calcul de norme\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    return gradient_penalty\n",
    "\n",
    "def DiscriminatorLoss(score_real, score_fake):\n",
    "    return torch.mean(score_fake) - torch.mean(score_real)\n",
    "\n",
    "def GeneratorLoss(predict_fake):\n",
    "    return -torch.mean(predict_fake)\n",
    "\n",
    "def DiversityLoss(fake_1, fake_2, z1, z2):\n",
    "    diff_img = torch.mean(torch.abs(fake_1 - fake_2))\n",
    "    diff_z = torch.mean(torch.abs(z1 - z2))\n",
    "\n",
    "    return - diff_img / (diff_z + 1e-8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14825109"
   },
   "source": [
    "### Entraînement du modèle\n",
    "\n",
    "Pour entraîner nos deux générateurset nos discriminateurs, il faut successivement générerles données, et les prédictions et calculer les loss de chaque sous-structure à chaque itération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dab9ca0"
   },
   "source": [
    "### Dataset fait maison\n",
    "\n",
    "Pour vérifier l'implémentation correcte des réseaux dans le cycle-GAN, on génère notre propres dataset. Pour respecter la relation entre les espaces $\\mathcal{X}$ et $\\mathcal{Y}$, le premier contiendra des vecteurs $x = [centre\\_x,\\:centre\\_y, rayon]$ et le deuxième contiendra une image d'un disque correspondant. L'objectif du cycle-GANS sera de lier les vecteurs $x$ correspondant aux images $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.369986Z",
     "iopub.status.busy": "2025-12-22T22:22:10.369750Z",
     "iopub.status.idle": "2025-12-22T22:22:10.385801Z",
     "shell.execute_reply": "2025-12-22T22:22:10.385236Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.369966Z"
    },
    "id": "e1996320",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SyntheticCircleDataset(Dataset):\n",
    "    def __init__(self, size=1000, img_dim=64):\n",
    "        self.size = size\n",
    "        self.img_dim = img_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Espace X : 3 paramètres aléatoires (x, y, rayon)\n",
    "        # Normalisés entre 0 et 1 (ou -1 et 1 selon tes besoins)\n",
    "        params = torch.rand(3)\n",
    "\n",
    "        # Espace Y : Génération de l'image correspondante (Simplifié)\n",
    "        # (Dans un vrai cas non-pairé, tu mélangerais les indices)\n",
    "        img = torch.zeros((1, self.img_dim, self.img_dim))\n",
    "\n",
    "        # Logique de dessin simple (juste pour l'exemple)\n",
    "        cx, cy = int(params[0]*self.img_dim), int(params[1]*self.img_dim)\n",
    "        r = int(params[2] * (self.img_dim/4))\n",
    "\n",
    "        y_grid, x_grid = torch.meshgrid(torch.arange(self.img_dim), torch.arange(self.img_dim), indexing='ij')\n",
    "        mask = ((x_grid - cx)**2 + (y_grid - cy)**2) <= r**2\n",
    "        img[0][mask] = 1.0\n",
    "\n",
    "        return params, img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.386912Z",
     "iopub.status.busy": "2025-12-22T22:22:10.386621Z",
     "iopub.status.idle": "2025-12-22T22:22:10.404494Z",
     "shell.execute_reply": "2025-12-22T22:22:10.403787Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.386892Z"
    },
    "id": "217d20a2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Instanciation du Dataset\n",
    "# On génère assez de données (ex: 5000 exemples)\n",
    "dataset = SyntheticCircleDataset(size=32*100, img_dim=32)\n",
    "\n",
    "# 2. Création des DataLoaders indépendants\n",
    "# On crée deux loaders distincts avec shuffle=True.\n",
    "# Comme ils sont mélangés différemment, le vecteur X du premier loader\n",
    "# ne correspondra pas à l'image Y du deuxième loader à l'instant t.\n",
    "# C'est ce qui simule le \"Non-Pairé\".\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader_X = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader_Y = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Création de l'itérateur pour Y (au cas où Y est plus petit que X)\n",
    "iter_Y = iter(train_loader_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.405581Z",
     "iopub.status.busy": "2025-12-22T22:22:10.405321Z",
     "iopub.status.idle": "2025-12-22T22:22:10.681563Z",
     "shell.execute_reply": "2025-12-22T22:22:10.680943Z",
     "shell.execute_reply.started": "2025-12-22T22:22:10.405550Z"
    },
    "id": "9cff9172",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paramètres réseaux\n",
    "z_dim = 50 # arbitraire\n",
    "x_dim = 3 # dimension du vecteur x\n",
    "x_ch = 512\n",
    "y_dim = 32 # arbitraire, tenseur 2D 64x64\n",
    "y_ch = 1 # noir et blanc\n",
    "init_dim = y_dim // (2**2)\n",
    "\n",
    "\n",
    "G = Generator_G(z_dim, x_dim, init_dim, ngf=1024).to(device=device)\n",
    "F = Generator_F(z_dim, x_dim, x_ch, y_ch, init_dim, nff=1024).to(device=device)\n",
    "DY = Discriminator_DY(y_ch, ndf=256).to(device=device)\n",
    "DX = Discriminator_DX(x_dim).to(device=device)\n",
    "\n",
    "# Paramètres de l'entraînement\n",
    "\n",
    "lr = 0.0001\n",
    "num_epochs = 100\n",
    "lambda_cycle = 200 # poids de la cycle_loss\n",
    "lambda_gp = 10 # poids de la gradient penalty\n",
    "lambda_div = 2 # poids pour le cout de diversité\n",
    "n_critic = 3 # ration entraînement discriminateurs/générateurs\n",
    "activ_div = num_epochs // 2\n",
    "\n",
    "b1 = 0.0  # paramètres ADAM recommandés par le papier\n",
    "b2 = 0.9\n",
    "\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(b1,b2))\n",
    "optimizer_F = torch.optim.Adam(F.parameters(), lr=lr, betas=(b1,b2))\n",
    "optimizer_DY = torch.optim.Adam(DY.parameters(), lr=lr, betas=(b1,b2))\n",
    "optimizer_DX = torch.optim.Adam(DX.parameters(), lr=lr, betas=(b1,b2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T22:22:10.682624Z",
     "iopub.status.busy": "2025-12-22T22:22:10.682401Z"
    },
    "id": "8760a786",
    "outputId": "c092da59-7545-468d-b1db-a974fa65faab",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss G : 1.8940273523330688\n",
      "Epoch: 0 Loss F : 0.19677366316318512\n",
      "Epoch: 0 Loss DY : -0.4865652322769165\n",
      "Epoch: 1 Loss G : 3.030085802078247\n",
      "Epoch: 1 Loss F : 0.01688380166888237\n",
      "Epoch: 1 Loss DY : -0.810099184513092\n",
      "Epoch: 2 Loss G : 2.8621327877044678\n",
      "Epoch: 2 Loss F : -0.013001516461372375\n",
      "Epoch: 2 Loss DY : -0.42043042182922363\n",
      "Epoch: 3 Loss G : 3.4332611560821533\n",
      "Epoch: 3 Loss F : 0.30852797627449036\n",
      "Epoch: 3 Loss DY : -0.759192705154419\n",
      "Epoch: 4 Loss G : 3.524346351623535\n",
      "Epoch: 4 Loss F : 0.39656734466552734\n",
      "Epoch: 4 Loss DY : -1.1618754863739014\n",
      "Epoch: 5 Loss G : 3.489110231399536\n",
      "Epoch: 5 Loss F : -0.21009743213653564\n",
      "Epoch: 5 Loss DY : -1.1372379064559937\n",
      "Epoch: 6 Loss G : 3.686211585998535\n",
      "Epoch: 6 Loss F : -0.22555077075958252\n",
      "Epoch: 6 Loss DY : -1.2384870052337646\n",
      "Epoch: 7 Loss G : 3.675940752029419\n",
      "Epoch: 7 Loss F : -0.1337355226278305\n",
      "Epoch: 7 Loss DY : -1.2538185119628906\n",
      "Epoch: 8 Loss G : 3.766140937805176\n",
      "Epoch: 8 Loss F : -0.937321662902832\n",
      "Epoch: 8 Loss DY : -1.2093335390090942\n",
      "Epoch: 9 Loss G : 3.7752609252929688\n",
      "Epoch: 9 Loss F : -0.6678308248519897\n",
      "Epoch: 9 Loss DY : -1.1255135536193848\n",
      "Epoch: 10 Loss G : 3.8961191177368164\n",
      "Epoch: 10 Loss F : -0.6016415953636169\n",
      "Epoch: 10 Loss DY : -1.481853723526001\n",
      "Epoch: 11 Loss G : 3.8759138584136963\n",
      "Epoch: 11 Loss F : -0.6533045172691345\n",
      "Epoch: 11 Loss DY : -1.143196702003479\n",
      "Epoch: 12 Loss G : 4.112783432006836\n",
      "Epoch: 12 Loss F : -0.6955219507217407\n",
      "Epoch: 12 Loss DY : -0.9828121662139893\n",
      "Epoch: 13 Loss G : 4.18273401260376\n",
      "Epoch: 13 Loss F : 0.2589763402938843\n",
      "Epoch: 13 Loss DY : -1.1007025241851807\n",
      "Epoch: 14 Loss G : 4.214501857757568\n",
      "Epoch: 14 Loss F : -0.17220667004585266\n",
      "Epoch: 14 Loss DY : -0.9792371988296509\n",
      "Epoch: 15 Loss G : 4.277613639831543\n",
      "Epoch: 15 Loss F : 0.30902519822120667\n",
      "Epoch: 15 Loss DY : -1.195014238357544\n",
      "Epoch: 16 Loss G : 4.309500694274902\n",
      "Epoch: 16 Loss F : -0.18232569098472595\n",
      "Epoch: 16 Loss DY : -1.021653175354004\n",
      "Epoch: 17 Loss G : 4.683815002441406\n",
      "Epoch: 17 Loss F : -0.09439490735530853\n",
      "Epoch: 17 Loss DY : -1.3720712661743164\n",
      "Epoch: 18 Loss G : 4.715783596038818\n",
      "Epoch: 18 Loss F : -0.30898064374923706\n",
      "Epoch: 18 Loss DY : -1.2546114921569824\n",
      "Epoch: 19 Loss G : 4.728677272796631\n",
      "Epoch: 19 Loss F : -0.29788637161254883\n",
      "Epoch: 19 Loss DY : -1.4339289665222168\n",
      "Epoch: 20 Loss G : 4.750602722167969\n",
      "Epoch: 20 Loss F : -0.3032577633857727\n",
      "Epoch: 20 Loss DY : -0.8860663771629333\n",
      "Epoch: 21 Loss G : 5.0383782386779785\n",
      "Epoch: 21 Loss F : -0.19471336901187897\n",
      "Epoch: 21 Loss DY : -0.986031174659729\n",
      "Epoch: 22 Loss G : 4.844596862792969\n",
      "Epoch: 22 Loss F : -0.13665899634361267\n",
      "Epoch: 22 Loss DY : -1.3821940422058105\n",
      "Epoch: 23 Loss G : 5.094459533691406\n",
      "Epoch: 23 Loss F : 0.12935204803943634\n",
      "Epoch: 23 Loss DY : -1.2907707691192627\n",
      "Epoch: 24 Loss G : 4.914626598358154\n",
      "Epoch: 24 Loss F : 0.07181648910045624\n",
      "Epoch: 24 Loss DY : -1.2288563251495361\n",
      "Epoch: 25 Loss G : 5.158646583557129\n",
      "Epoch: 25 Loss F : -0.25448572635650635\n",
      "Epoch: 25 Loss DY : -1.0913413763046265\n",
      "Epoch: 26 Loss G : 5.3671441078186035\n",
      "Epoch: 26 Loss F : -0.08913449198007584\n",
      "Epoch: 26 Loss DY : -1.065921425819397\n",
      "Epoch: 27 Loss G : 5.276434421539307\n",
      "Epoch: 27 Loss F : -0.5083183646202087\n",
      "Epoch: 27 Loss DY : -1.093664526939392\n",
      "Epoch: 28 Loss G : 5.350527286529541\n",
      "Epoch: 28 Loss F : -0.3768654465675354\n",
      "Epoch: 28 Loss DY : -0.9496847987174988\n",
      "Epoch: 29 Loss G : 5.51410436630249\n",
      "Epoch: 29 Loss F : -0.6162269115447998\n",
      "Epoch: 29 Loss DY : -1.4514302015304565\n",
      "Epoch: 30 Loss G : 5.6698808670043945\n",
      "Epoch: 30 Loss F : -0.35296642780303955\n",
      "Epoch: 30 Loss DY : -1.2926993370056152\n",
      "Epoch: 31 Loss G : 5.637596607208252\n",
      "Epoch: 31 Loss F : -0.5007110834121704\n",
      "Epoch: 31 Loss DY : -1.6002216339111328\n",
      "Epoch: 32 Loss G : 5.660514831542969\n",
      "Epoch: 32 Loss F : -0.2750883400440216\n",
      "Epoch: 32 Loss DY : -1.4754714965820312\n",
      "Epoch: 33 Loss G : 5.802523136138916\n",
      "Epoch: 33 Loss F : -0.45318469405174255\n",
      "Epoch: 33 Loss DY : -1.2703392505645752\n",
      "Epoch: 34 Loss G : 5.883781433105469\n",
      "Epoch: 34 Loss F : -0.31411027908325195\n",
      "Epoch: 34 Loss DY : -1.2936599254608154\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (real_x, _) in enumerate(train_loader_X):\n",
    "\n",
    "        try:\n",
    "            _, real_y = next(iter_Y)\n",
    "        except StopIteration:\n",
    "            # Si on a fini le dataset Y, on le recharge\n",
    "            iter_Y = iter(train_loader_Y)\n",
    "            _, real_y = next(iter_Y)\n",
    "\n",
    "        real_x = real_x.to(device)\n",
    "        real_y = real_y.to(device)\n",
    "\n",
    "        # normalisation etre -1 et 1\n",
    "        real_x = real_x.to(device)\n",
    "        real_x = (real_x * 2) - 1\n",
    "        real_y = real_y.to(device)\n",
    "        real_y = (real_y * 2) - 1\n",
    "\n",
    "\n",
    "        # activation de la diversity_loss\n",
    "        if epoch >= activ_div:\n",
    "            poids_div = lambda_div\n",
    "        else:\n",
    "            poids_div = 0\n",
    "\n",
    "        # on s'assure qu'ils aient les bonnes dimensions\n",
    "        # real_x = ...\n",
    "        # real_y = ...\n",
    "\n",
    "        with torch.no_grad(): # on ne veut que les gradients des générateurs soient calculés pour l'instant\n",
    "            z_x = torch.randn(batch_size, z_dim).to(device)\n",
    "            z_y = torch.randn(batch_size, z_dim).to(device)\n",
    "            fake_x = F(real_y, z_y)\n",
    "            fake_y = G(real_x, z_x)\n",
    "        # print(real_x.size())\n",
    "        # print(fake_x.size())\n",
    "\n",
    "        ### ENTRAINEMENT DISCRIMINATEURS\n",
    "        optimizer_DY.zero_grad()\n",
    "        optimizer_DX.zero_grad()\n",
    "\n",
    "        # Discriminateur DY\n",
    "        score_real_Y = DY(real_y) # les discriminateurs sortent des scores, pas des prédictions\n",
    "        score_fake_Y = DY(fake_y.detach()) # detach() --> on ne veut pas que le gradient remonte au générateur\n",
    "        # Loss WGAN : E[D(fake)] - E[D(real)] + lambda * GP\n",
    "        loss_DY = DiscriminatorLoss(score_real_Y, score_fake_Y) + lambda_gp * GradientPenalty(DY, real_y,fake_y.detach())\n",
    "        loss_DY.backward()\n",
    "        optimizer_DY.step()\n",
    "\n",
    "        # Discriminateur DX\n",
    "        score_real_X = DX(real_x) # les discriminateurs sortent des scores, pas des prédictions\n",
    "        score_fake_X = DX(fake_x.detach()) # detach() --> on ne veut pas que le gradient remonte au générateur\n",
    "        # Loss WGAN : E[D(fake)] - E[D(real)] + lambda * GP\n",
    "        loss_DX = DiscriminatorLoss(score_real_X, score_fake_X) + lambda_gp * GradientPenalty(DX, real_x,fake_x.detach())\n",
    "        loss_DX.backward()\n",
    "        optimizer_DX.step()\n",
    "\n",
    "        ### ENTRAINEMENT GENERATEURS\n",
    "        if i % n_critic == 0:\n",
    "            optimizer_G.zero_grad()\n",
    "            optimizer_F.zero_grad()\n",
    "\n",
    "\n",
    "            z_x = torch.randn(batch_size, z_dim).to(device)\n",
    "            z_x2 = torch.randn_like(z_x).to(device)\n",
    "            fake_x = F(real_y, z_y)\n",
    "            z_y = torch.randn(batch_size, z_dim).to(device)\n",
    "            z_y2 = torch.randn_like(z_y).to(device)\n",
    "            fake_y = G(real_x, z_x)\n",
    "\n",
    "            # Calcul des GAN-Loss --> tromper le discriminateur\n",
    "            # Le générateur veut maximiser D(fake), donc minimiser -D(fake)\n",
    "            predict_fake_Y = DY(fake_y)\n",
    "            Loss_GAN_G = GeneratorLoss(predict_fake_Y)\n",
    "            predict_fake_X = DX(fake_x)\n",
    "            Loss_GAN_F = GeneratorLoss(predict_fake_X)\n",
    "\n",
    "            # Calcul de Cycle-Loss --> pour revenir à l'espace de départ\n",
    "            reconstructed_x = F(fake_y, z_y)\n",
    "            Loss_cycle_X = CycleLoss(real_x, reconstructed_x)\n",
    "            reconstructed_y = G(fake_x, z_x)\n",
    "            Loss_cycle_Y = CycleLoss(real_y, reconstructed_y)\n",
    "\n",
    "            # Calcul de Diversity-Loss\n",
    "            fake_x2 = F(real_y, z_y2)\n",
    "            Loss_div_F = DiversityLoss(fake_x, fake_x2, z_x, z_x2)\n",
    "            fake_y2 = G(real_x, z_x2)\n",
    "            Loss_div_G = DiversityLoss(fake_y, fake_y2, z_y, z_y2)\n",
    "\n",
    "            # Loss totale\n",
    "            Loss_Generator = Loss_GAN_G + Loss_GAN_F + lambda_cycle*(Loss_cycle_X + Loss_cycle_Y) + poids_div*(Loss_div_F + Loss_div_G)\n",
    "            Loss_Generator.backward()\n",
    "            optimizer_G.step()\n",
    "            optimizer_F.step()\n",
    "\n",
    "        # Show loss\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch: {epoch} Loss G : {Loss_GAN_G}\")\n",
    "        print(f\"Epoch: {epoch} Loss F : {Loss_GAN_F}\")\n",
    "        print(f\"Epoch: {epoch} Loss DY : {loss_DY}\")\n",
    "        # print(f\"Epoch: {epoch} Loss DX : {loss_DX}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "125368b7"
   },
   "source": [
    "# Inférence Cycle-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def show_5_comparisons(G, z_dim, device, img_dim=64):\n",
    "    n_samples = 5\n",
    "    \n",
    "    # 1. Création des conditions aléatoires (Batch de 5)\n",
    "    # x_vals est entre [0, 1] pour faciliter le calcul des coordonnées\n",
    "    x_vals = torch.rand(n_samples, 3).to(device) \n",
    "    \n",
    "    # 2. Préparation pour le GAN (x doit être entre -1 et 1 comme vu précédemment)\n",
    "    x_for_gan = (x_vals * 2) - 1\n",
    "    z_noise = torch.randn(n_samples, z_dim).to(device)\n",
    "    \n",
    "    # 3. Génération (Batch)\n",
    "    with torch.no_grad():\n",
    "        fake_imgs = G(x_for_gan, z_noise).cpu().squeeze() # (5, 64, 64)\n",
    "\n",
    "    # 4. Création des \"Vraies\" images théoriques\n",
    "    real_imgs = []\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(img_dim), torch.arange(img_dim), indexing='ij')\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        img = torch.zeros((img_dim, img_dim))\n",
    "        \n",
    "        # On récupère les scalaires pour chaque sample\n",
    "        cx = int(x_vals[i, 0] * img_dim)\n",
    "        cy = int(x_vals[i, 1] * img_dim)\n",
    "        r = int(x_vals[i, 2] * (img_dim / 4))\n",
    "        \n",
    "        mask = ((x_grid - cx)**2 + (y_grid - cy)**2) <= r**2\n",
    "        img[mask] = 1.0\n",
    "        real_imgs.append(img)\n",
    "\n",
    "    # 5. Affichage\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Ligne du haut : Vraie Image (Cible)\n",
    "        axes[0, i].imshow(real_imgs[i], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 2: axes[0, i].set_title(\"Cibles Théoriques (Dataset)\", fontsize=12)\n",
    "\n",
    "        # Ligne du bas : Image Générée\n",
    "        # Dénormalisation de la sortie du GAN (-1,1 -> 0,1)\n",
    "        gen_img = (fake_imgs[i] + 1) / 2\n",
    "        axes[1, i].imshow(gen_img, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 2: axes[1, i].set_title(\"Générations (GAN)\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Utilisation\n",
    "show_5_comparisons(G, z_dim, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
